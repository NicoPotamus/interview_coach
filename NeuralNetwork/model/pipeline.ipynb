{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program uses spaCy's pretrained pipeline to fine tune the model for our application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and load the spacy model\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher, Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "from spacy.language import Language\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "import csv\n",
    "\n",
    "#getting the data from the csv and turning it into text that can be manipulated by spaCy's pipeline\n",
    "TEXTS = []\n",
    "with open(\"../data/related_skills.csv\", mode='r') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    next(reader)  # Skip the first row\n",
    "    for row in reader:\n",
    "        TEXTS.extend(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to add a component before the data gets to the NER model\n",
    "we want to add patterns to the model for the it to identify in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating pattern\n",
    "skills_patterns = list(nlp.pipe(TEXTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a certified\n",
      "network certified\n",
      "laptops\n",
      "n certified\n",
      "computer hardware\n",
      "windows 7\n",
      "comptia\n",
      "troubleshooting\n",
      "software installation\n",
      "printers\n",
      "xp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#just printing the first few skills in the list\n",
    "i = 0\n",
    "while i <= 10:\n",
    "    print(skills_patterns[i].text)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"SKILL\", skills_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the component...we may have to take a different approach\n",
    "@Language.component(\"skills_component\")\n",
    "def skills_component_function(doc):\n",
    "    #applying matcher to the doc\n",
    "    matches = matcher(doc)\n",
    "    #creating the span for each match and assigning the label \"SKILL\"\n",
    "    spans = [Span(doc, start, end, label = \"SKILL\") for match_id, start, end in matches]\n",
    "    #were going to overite the doc.ents with our new spans\n",
    "    doc.ents = spans \n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'skills_component', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# add 2 pipeline\n",
    "nlp.add_pipe(\"skills_component\", after=\"lemmatizer\"),\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('java', 'SKILL')]\n",
      "[('java', 'SKILL'), ('communication', 'SKILL')]\n",
      "[('programmers', 'SKILL'), ('team', 'SKILL'), ('code', 'SKILL'), ('building', 'SKILL'), ('write', 'SKILL'), ('code', 'SKILL'), ('Python', 'ORG'), ('JavaScript', 'PRODUCT'), ('at least one', 'CARDINAL'), ('programming', 'SKILL'), ('language', 'SKILL'), ('JavaScript', 'PRODUCT'), ('Python', 'ORG'), ('C++', 'LANGUAGE'), ('HTML', 'ORG'), ('SQL', 'ORG'), ('Swift', 'PRODUCT'), ('coding', 'SKILL'), ('HackerRank', 'ORG'), ('etc', 'SKILL'), ('coding', 'SKILL'), ('application', 'SKILL'), ('process', 'SKILL'), ('assessment', 'SKILL'), ('access', 'SKILL'), ('projects', 'SKILL'), ('quality', 'SKILL'), ('projects', 'SKILL'), ('5-20 hours', 'TIME'), ('up to 40 hours', 'TIME')]\n",
      "[('experienced', 'SKILL'), ('construction', 'SKILL'), ('team', 'SKILL'), ('projects', 'SKILL'), ('city', 'SKILL')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E1010] Unable to set entity information for token 10 which is included in more than one span in entities, blocked, missing or outside.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m TEXTS \u001b[38;5;241m=\u001b[39m [text, text2]\u001b[38;5;66;03m#, text3, text4, text5, text6, text7]\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m TEXTS:\n\u001b[0;32m---> 24\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m([(ent\u001b[38;5;241m.\u001b[39mtext, ent\u001b[38;5;241m.\u001b[39mlabel_) \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39ments])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/spacy/language.py:1057\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1057\u001b[0m     \u001b[43merror_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, Doc):\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE005\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, returned_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(doc)))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/spacy/util.py:1722\u001b[0m, in \u001b[0;36mraise_error\u001b[0;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[0;32m-> 1722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/spacy/language.py:1052\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1052\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mskills_component_function\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      7\u001b[0m spans \u001b[38;5;241m=\u001b[39m [Span(doc, start, end, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSKILL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m match_id, start, end \u001b[38;5;129;01min\u001b[39;00m matches]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#were going to overite the doc.ents with our new spans\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ments\u001b[49m \u001b[38;5;241m=\u001b[39m spans \n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/spacy/tokens/doc.pyx:798\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/spacy/tokens/doc.pyx:835\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E1010] Unable to set entity information for token 10 which is included in more than one span in entities, blocked, missing or outside."
     ]
    }
   ],
   "source": [
    "# Process test text and print the text and label for the doc.ents\n",
    "doc = nlp(\"java is required, looking for IT specialist\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "\n",
    "doc = nlp(\"java is required, Good communication\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "doc = nlp(\"We are looking for proficient programmers to join our team to train our AI chatbots to code. You will work with the chatbots that we are building in order to measure their progress, as well as write and evaluate code.To apply to this role, you will need to be proficient in either Python and/or JavaScript. Your role will require proficiency in at least one programming language (JavaScript, Python, C#, C++, HTML, SQL, or Swift) in order to solve coding problems (think LeetCode, HackerRank, etc). For each coding problem, you must be able to explain how your solution solves the problem.As part of the application process, you will be asked to complete an assessment. If you pass, you will gain access to projects. Based on the quality of your work, you will continue to receive projects regularly. We find our most successful candidates work between 5-20 hours per week, up to 40 hours.\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "\n",
    "# This is a description taken from the api\n",
    "text = \"We are looking for experienced and skilled construction workers to join our team on various projects across the city.\" \n",
    "text2 =  \"Candidates must possess strong problem-solving skills ability to work independently and as part of a team, attention to detail, and a commitment to safety at all times.\"\n",
    "# text3 = \"Duties include site preparation, laying foundations, installing utilities, framing structures, roofing, plumbing, electrical work, finish carpentry, and painting.\"\n",
    "# text4 = \"Previous experience in commercial or residential construction is preferred but not required for entry-level positions.\"\n",
    "# text5 = \"Hours may vary depending on the project, with potential overtime available during peak periods.\" \n",
    "# text6 = \"Competitive compensation packages include health insurance, retirement plan options, paid vacation time, and opportunities for advancement within our company.\" \n",
    "# text7 = \"If you are passionate about construction and committed to excellence, please submit your resume along with references for consideration.\"\n",
    "TEXTS = [text, text2]#, text3, text4, text5, text6, text7]\n",
    "\n",
    "for text in TEXTS:\n",
    "    doc = nlp(text)\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
