{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import html\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy blank model for tokenization alignment checking\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")  # Case-insensitive matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load skills from a linkedin skills file\n",
    "skill_file = \"../data/linkedin_skills.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(skill_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    skill_list = [line.strip() for line in f.readlines() if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean skills (Fix HTML entities, handle hyphens, preserve single letters)\n",
    "def clean_skill(skill):\n",
    "    skill = html.unescape(skill)  # Convert HTML entities (&amp; -> &)\n",
    "    skill = skill.replace(\"\\t\", \" \").strip()  # Remove tabs and extra spaces\n",
    "    skill = re.sub(r\"\\s+\", \" \", skill)  # Normalize multiple spaces\n",
    "\n",
    "    # Normalize ampersands to \"and\"\n",
    "    skill = skill.replace(\"&\", \"and\")  \n",
    "\n",
    "    # Convert hyphens to spaces for better tokenization\n",
    "    skill = skill.replace(\"-\", \" \")  \n",
    "\n",
    "    # Preserve single-letter words (e.g., \"v\" in \"hyper v\") by adding \"_\"\n",
    "    skill = re.sub(r\"\\b([a-zA-Z])\\b\", r\"\\1_\", skill)  \n",
    "\n",
    "    # Normalize apostrophes to avoid tokenization errors\n",
    "    skill = skill.replace(\"’\", \"'\")  # Normalize different apostrophe characters\n",
    "\n",
    "    return skill.lower().strip()  # Convert to lowercase for better matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence templates\n",
    "# This is a temporary approach until we get live data coming in\n",
    "sentence_templates = [\n",
    "    \"{} is a required skill for this position.\",\n",
    "    \"Candidates should have expertise in {}.\",\n",
    "    \"Proficiency in {} is essential for this job.\",\n",
    "    \"A background in {} is strongly preferred.\",\n",
    "    \"We are looking for applicants skilled in {}.\",\n",
    "    \"Experience with {} is a significant advantage.\",\n",
    "    \"{} knowledge is a key qualification.\",\n",
    "    \"An ideal candidate must be proficient in {}.\",\n",
    "    \"Knowledge of {} is required for this role.\",\n",
    "    \"{} is an important skill for candidates.\",\n",
    "    \"Candidates should demonstrate strong {} skills.\",\n",
    "    \"Proficiency in {} is preferred by employers.\",\n",
    "    \"Having a solid background in {} will be beneficial.\",\n",
    "    \"{} is a valuable skill for this position.\",\n",
    "    \"Having experience in {} will be beneficial.\",\n",
    "    \"Familiarity with {} is a must-have for this role.\",\n",
    "    \"Candidates should be well-versed in {}.\",\n",
    "    \"Employers seek professionals with {} expertise.\",\n",
    "    \"A solid foundation in {} is required.\",\n",
    "    \"{} is highly valued in this industry.\",\n",
    "    \"Strong {} skills are necessary for success in this role.\",\n",
    "    \"Understanding {} is crucial for this job.\",\n",
    "    \"Applicants must demonstrate competency in {}.\",\n",
    "    \"A candidate must be experienced in {}.\",\n",
    "    \"{} proficiency will help you excel in this role.\",\n",
    "    \"The ability to work with {} is a must-have for this position.\",\n",
    "    \"We are prioritizing candidates familiar with {}.\",\n",
    "    \"Employers value professionals who are skilled in {}.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function\n",
    "skill_list = [clean_skill(skill) for skill in skill_list]\n",
    "\n",
    "# ✅ Use PhraseMatcher to add skills for proper tokenization\n",
    "skill_patterns = [nlp.make_doc(skill) for skill in skill_list]\n",
    "matcher.add(\"SKILL\", skill_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(skill_list, sentence_templates, num_sentences=5000):\n",
    "    \"\"\"Generates labeled training data for spaCy's NER model\"\"\"\n",
    "    training_data = []\n",
    "    used_sentences = set()\n",
    "\n",
    "    while len(training_data) < num_sentences:\n",
    "        skill = random.choice(skill_list)\n",
    "        skill = clean_skill(skill)  # Ensure skill is cleaned\n",
    "\n",
    "        if not skill or len(skill) < 2:\n",
    "            continue  # Skip invalid skills\n",
    "\n",
    "        template = random.choice(sentence_templates)\n",
    "        sentence = template.format(skill)\n",
    "\n",
    "        # Ensure uniqueness to prevent duplicate patterns\n",
    "        if sentence in used_sentences:\n",
    "            continue\n",
    "        used_sentences.add(sentence)\n",
    "\n",
    "        # Tokenize sentence using spaCy's tokenizer\n",
    "        doc = nlp(sentence)\n",
    "        tokenized_sentence = \" \".join([token.text.lower() for token in doc])\n",
    "\n",
    "        # Ensure skills like \"hyper v\" are matched correctly\n",
    "        matches = matcher(doc)\n",
    "        matched_entities = []\n",
    "        for match_id, start, end in matches:\n",
    "            span = doc[start:end]\n",
    "            if skill.lower() in span.text.lower():\n",
    "                matched_entities.append((span.start_char, span.end_char, \"SKILL\"))\n",
    "\n",
    "        if not matched_entities:\n",
    "            print(f\"Skipping misaligned skill: '{skill}' in sentence: '{sentence}'\")\n",
    "            continue  # Skip misaligned skill\n",
    "\n",
    "        training_data.append((sentence, {\"entities\": matched_entities}))\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping misaligned skill: 'ima' in sentence: 'Applicants must demonstrate competency in ima.'\n"
     ]
    }
   ],
   "source": [
    "# Generate training data\n",
    "training_data = generate_training_data(skill_list, sentence_templates, num_sentences=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labeled data in spaCy format\n",
    "output_file = \"../data/spacy_training_data.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(training_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labeled training data saved to ../data/spacy_training_data.json with 20000 sentences!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labeled training data saved to {output_file} with {len(training_data)} sentences!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
